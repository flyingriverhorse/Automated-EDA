"""Dataset Shape Analysis Component.

Provides detailed analysis of dataset dimensions including rows, columns,
memory usage, and basic structural information.
"""


class DatasetShapeAnalysis:
    """Analyze dataset dimensions and basic structure."""
    
    @staticmethod
    def get_metadata():
        return {
            "name": "dataset_shape_analysis",
            "display_name": "Dataset Shape Analysis", 
            "description": "Inspect dataset dimensions (rows, columns) and basic structure",
            "category": "data_quality",
            "complexity": "basic",
            "tags": ["shape", "dimensions", "structure", "overview"],
            "estimated_runtime": "< 1 second",
            "icon": "üìä"
        }
    
    @staticmethod
    def validate_data_compatibility(data_preview=None):
        """Check if analysis can be performed on the data."""
        return True  # Works with any dataset
    
    @staticmethod
    def generate_code(data_preview=None):
        """Generate code for dataset shape analysis."""
        
        return '''
# ===== DATASET SHAPE ANALYSIS =====

import pandas as pd
import numpy as np

print("="*60)
print("üìä DATASET SHAPE AND STRUCTURE ANALYSIS")  
print("="*60)

# Basic shape information
print(f"\\nüìè Dataset Dimensions:")
print(f"   ‚Ä¢ Rows: {df.shape[0]:,}")
print(f"   ‚Ä¢ Columns: {df.shape[1]:,}")
print(f"   ‚Ä¢ Total cells: {df.shape[0] * df.shape[1]:,}")

# Memory usage analysis
print(f"\\nüíæ Memory Usage:")
memory_usage = df.memory_usage(deep=True)
total_memory = memory_usage.sum()

if total_memory > 1024**3:  # GB
    print(f"   ‚Ä¢ Total memory: {total_memory / (1024**3):.2f} GB")
elif total_memory > 1024**2:  # MB  
    print(f"   ‚Ä¢ Total memory: {total_memory / (1024**2):.2f} MB")
else:  # KB
    print(f"   ‚Ä¢ Total memory: {total_memory / 1024:.2f} KB")

print(f"   ‚Ä¢ Average memory per row: {total_memory / df.shape[0]:.2f} bytes")

# Column information summary
print(f"\\nüìã Column Overview:")
print(f"   ‚Ä¢ Numeric columns: {len(df.select_dtypes(include=[np.number]).columns)}")
print(f"   ‚Ä¢ Text/Object columns: {len(df.select_dtypes(include=['object']).columns)}")
print(f"   ‚Ä¢ DateTime columns: {len(df.select_dtypes(include=['datetime64']).columns)}")
print(f"   ‚Ä¢ Boolean columns: {len(df.select_dtypes(include=['bool']).columns)}")

# Data sparsity
non_null_count = df.count().sum()
total_cells = df.shape[0] * df.shape[1]
completeness = (non_null_count / total_cells) * 100

print(f"\\n‚úÖ Data Completeness:")
print(f"   ‚Ä¢ Non-null cells: {non_null_count:,} ({completeness:.1f}%)")
print(f"   ‚Ä¢ Null cells: {total_cells - non_null_count:,} ({100-completeness:.1f}%)")

# Quick preview of column names
print(f"\\nüìù Column Names Preview:")
if df.shape[1] <= 10:
    for i, col in enumerate(df.columns, 1):
        print(f"   {i:2d}. {col}")
else:
    for i, col in enumerate(df.columns[:8], 1):  # Show first 8 columns (increased from 5)
        print(f"   {i:2d}. {col}")
    print(f"   ... ({df.shape[1] - 10} more columns)")
    for i, col in enumerate(df.columns[-5:], df.shape[1]-4):
        print(f"   {i:2d}. {col}")

print("\\n" + "="*60)
print("‚úÖ Dataset shape analysis complete!")
print("="*60)
'''


def get_component():
    """Return the analysis component."""
    return DatasetShapeAnalysis